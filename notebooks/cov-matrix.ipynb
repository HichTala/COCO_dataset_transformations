{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T14:57:28.941119474Z",
     "start_time": "2024-01-18T14:57:28.681339646Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def KL_divergence(mean1, mean2, covariance2, precision1, precision2):\n",
    "    assert precision1.shape == covariance2.shape\n",
    "    d = precision1.shape[0]\n",
    "    mean1 = mean1.type(torch.float64)\n",
    "    mean2 = mean2.type(torch.float64)\n",
    "    precision1 = precision1.type(torch.float64)\n",
    "    covariance2 = covariance2.type(torch.float64)\n",
    "    product = covariance2 @ precision1\n",
    "    scal_prod = torch.t(mean2 - mean1) @ precision2 @ (mean2 - mean1)\n",
    "    return 1 / 2 * torch.logdet(product) - d / 2 + 1 / 2 * torch.trace(product) + 1 / 2 * scal_prod"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T15:20:08.478580487Z",
     "start_time": "2024-01-18T15:20:08.437195597Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([5, 8, 9, 13, 14, 12, 2, 7, 6, 1, 10, 4, 0, 3, 15, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": "(10, 1024)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'DOTA_train'\n",
    "\n",
    "class_features = {}\n",
    "\n",
    "classes = os.listdir(os.path.join('../class_features', dataset))\n",
    "for c in classes:\n",
    "    class_features[int(c)] = []\n",
    "    for i in range(10):\n",
    "        with open(os.path.join('../class_features', dataset, c, str(i) + '.pkl'), 'rb') as f:\n",
    "            image_f = pickle.load(f)\n",
    "        class_features[int(c)].append(image_f.squeeze().cpu().numpy())\n",
    "    class_features[int(c)] = np.array(class_features[int(c)])\n",
    "\n",
    "print(class_features.keys())\n",
    "class_features[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T15:06:02.401713463Z",
     "start_time": "2024-01-18T15:06:02.357356909Z"
    }
   },
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.71it/s]\n",
      "100%|██████████| 16/16 [00:03<00:00,  4.91it/s]\n"
     ]
    }
   ],
   "source": [
    "bgmm_dict = {}\n",
    "\n",
    "classes = list(map(int, os.listdir(os.path.join('../class_features', dataset))))\n",
    "for c in tqdm(classes):\n",
    "    bgmm = BayesianGaussianMixture()\n",
    "    bgmm.fit(class_features[c])\n",
    "    bgmm_dict[c] = bgmm\n",
    "\n",
    "n = len(classes)\n",
    "heatmap = np.zeros((n, n))\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    mean1 = torch.tensor(bgmm_dict[i].means_).squeeze()\n",
    "    covariance1 = torch.tensor(bgmm_dict[i].covariances_).squeeze()\n",
    "    precision1 = torch.tensor(bgmm_dict[i].precisions_).squeeze()\n",
    "    for j in range(n):\n",
    "        mean2 = torch.tensor(bgmm_dict[j].means_).squeeze()\n",
    "        covariance2 = torch.tensor(bgmm_dict[j].covariances_).squeeze()\n",
    "        precision2 = torch.tensor(bgmm_dict[j].precisions_).squeeze()\n",
    "        # heatmap1[i, j], heatmap2[i, j], heatmap3[i, j], heatmap[i, j] = KL_divergence_pinv(mean1, mean2, covariance1, covariance2)\n",
    "        try:\n",
    "            heatmap[i, j] = KL_divergence(mean1, mean2, covariance2, precision1, precision2)\n",
    "        except torch._C._LinAlgError:\n",
    "            heatmap[i, j] = np.nan\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T15:20:32.643716593Z",
     "start_time": "2024-01-18T15:20:25.974950547Z"
    }
   },
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "0 plane,\n",
    "1 ship,\n",
    "2 storage tank,\n",
    "3 baseball diamond,\n",
    "4 tennis court,\n",
    "5 basketball court,\n",
    "6 ground track field,\n",
    "7 harbor, \n",
    "8 bridge,\n",
    "9 large vehicle,\n",
    "10 small vehicle,\n",
    "11 helicopter, \n",
    "12 roundabout,\n",
    "13 soccer ball field,\n",
    "14 swimming pool \n",
    "15 container crane"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T15:35:18.507276190Z",
     "start_time": "2024-01-18T15:35:18.446543899Z"
    }
   },
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f8fb11a7d10>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "plt.imshow(heatmap)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T15:35:20.459949516Z",
     "start_time": "2024-01-18T15:35:20.458082988Z"
    }
   },
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def KL_divergence_pinv(mean1, mean2, covariance1, covariance2):\n",
    "    assert covariance1.shape == covariance2.shape\n",
    "    d = covariance1.shape[0]\n",
    "    mean1 = mean1.type(torch.float64)\n",
    "    mean2 = mean2.type(torch.float64)\n",
    "    covariance1 = covariance1.type(torch.float64)\n",
    "    covariance2 = covariance2.type(torch.float64)\n",
    "    cov1_bis = covariance1 + torch.eye(1024, device='cuda:0') * 1e-6\n",
    "    cov2_bis = covariance2 + torch.eye(1024, device='cuda:0') * 1e-6\n",
    "    product1 = cov2_bis @ torch.linalg.pinv(cov1_bis, atol=1e-7, hermitian=True)\n",
    "    product2 = covariance2 @ torch.linalg.pinv(covariance1, atol=1e-7, hermitian=True)\n",
    "    scal_prod = torch.t(mean2 - mean1) @ torch.linalg.pinv(covariance2, atol=1e-6, hermitian=True) @ (mean2 - mean1)\n",
    "    lndet = torch.logdet(product1)\n",
    "    trace = torch.trace(product2) + (\n",
    "            1024 - torch.linalg.matrix_rank(torch.linalg.pinv(covariance1, atol=1e-7, hermitian=True)))\n",
    "    return lndet, trace, scal_prod, 1 / 2 * (lndet - d + trace + scal_prod)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def KL_divergence_std(mean1, mean2, variance1, variance2):\n",
    "    assert variance1.shape == variance2.shape\n",
    "    d = variance1.shape[0]\n",
    "    mean1 = mean1.type(torch.float64)\n",
    "    mean2 = mean2.type(torch.float64)\n",
    "    variance1 = variance1.type(torch.float64) * torch.eye(d, device='cuda:0')\n",
    "    variance2 = variance2.type(torch.float64) * torch.eye(d, device='cuda:0')\n",
    "    product = variance2 @ torch.linalg.inv(variance1)\n",
    "    scal_prod = torch.t(mean2 - mean1) @ torch.linalg.inv(variance2) @ (mean2 - mean1)\n",
    "    return 1 / 2 * torch.logdet(product) - d / 2 + 1 / 2 * torch.trace(product) + 1 / 2 * scal_prod"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T15:27:56.931004563Z",
     "start_time": "2024-01-18T15:27:56.887164755Z"
    }
   },
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './class_barycenter'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[50], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m paths \u001B[38;5;241m=\u001B[39m [os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./class_barycenter\u001B[39m\u001B[38;5;124m'\u001B[39m, dataset) \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39mlistdir(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./class_barycenter\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n\u001B[1;32m      2\u001B[0m heatmaps \u001B[38;5;241m=\u001B[39m {}\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './class_barycenter'"
     ]
    }
   ],
   "source": [
    "paths = [os.path.join('./class_barycenter', dataset) for dataset in os.listdir('./class_barycenter')]\n",
    "heatmaps = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T15:27:58.282748471Z",
     "start_time": "2024-01-18T15:27:58.263957174Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    print(path)\n",
    "    mean = [x for x in sorted(os.listdir(path),\n",
    "                              key=lambda item: (int(item.partition('_')[0])\n",
    "                                                if item[0].isdigit() else float('inf'), item))\n",
    "            if x.split('_')[1] == 'mean.pkl']\n",
    "\n",
    "    cov = [x for x in sorted(os.listdir(path),\n",
    "                             key=lambda item: (int(item.partition('_')[0])\n",
    "                                               if item[0].isdigit() else float('inf'), item))\n",
    "           if x.split('_')[1] == 'cov.pkl']\n",
    "\n",
    "    n = len(mean)\n",
    "    heatmap = np.zeros((n, n))\n",
    "\n",
    "    for i in tqdm(range(n)):\n",
    "        mean1_path = os.path.join(path, mean[i])\n",
    "        cov1_path = os.path.join(path, cov[i])\n",
    "        with open(mean1_path, 'rb') as f:\n",
    "            mean1 = pickle.load(f)\n",
    "        with open(cov1_path, 'rb') as f:\n",
    "            covariance1 = pickle.load(f)\n",
    "        for j in range(n):\n",
    "            mean2_path = os.path.join(path, mean[j])\n",
    "            cov2_path = os.path.join(path, cov[j])\n",
    "            with open(mean2_path, 'rb') as f:\n",
    "                mean2 = pickle.load(f)\n",
    "            with open(cov2_path, 'rb') as f:\n",
    "                covariance2 = pickle.load(f)\n",
    "\n",
    "            # heatmap1[i, j], heatmap2[i, j], heatmap3[i, j], heatmap[i, j] = KL_divergence_pinv(mean1, mean2, covariance1, covariance2)\n",
    "            try:\n",
    "                heatmap[i, j] = KL_divergence_std(mean1, mean2, covariance1, covariance2)\n",
    "            except torch._C._LinAlgError:\n",
    "                heatmap[i, j] = np.nan\n",
    "    heatmaps[path.split('/')[-1]] = heatmap"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(heatmaps[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig = plt.figure()\n",
    "\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols=(7, 6),\n",
    "                axes_pad=0.5,\n",
    "                share_all=True,\n",
    "                cbar_location=\"right\",\n",
    "                cbar_mode=\"single\",\n",
    "                )\n",
    "keys = sorted(list(heatmaps.keys()))[2:] + ['COCO_train', 'COCO_val']\n",
    "\n",
    "for dataset, ax in zip(keys, grid):\n",
    "    ax.set_title(dataset)\n",
    "    im = ax.imshow(heatmaps[dataset])\n",
    "\n",
    "grid.cbar_axes[0].colorbar(im)\n",
    "\n",
    "for cax in grid.cbar_axes:\n",
    "    cax.toggle_label(True)\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = len(mean)\n",
    "heatmap = np.zeros((n, n))\n",
    "heatmap1 = np.zeros((n, n))\n",
    "heatmap2 = np.zeros((n, n))\n",
    "heatmap3 = np.zeros((n, n))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in tqdm(range(n)):\n",
    "    mean1_path = os.path.join(path, mean[i])\n",
    "    cov1_path = os.path.join(path, cov[i])\n",
    "    with open(mean1_path, 'rb') as f:\n",
    "        mean1 = pickle.load(f)\n",
    "    with open(cov1_path, 'rb') as f:\n",
    "        covariance1 = pickle.load(f)\n",
    "    for j in range(n):\n",
    "        mean2_path = os.path.join(path, mean[j])\n",
    "        cov2_path = os.path.join(path, cov[j])\n",
    "        with open(mean2_path, 'rb') as f:\n",
    "            mean2 = pickle.load(f)\n",
    "        with open(cov2_path, 'rb') as f:\n",
    "            covariance2 = pickle.load(f)\n",
    "\n",
    "        # heatmap1[i, j], heatmap2[i, j], heatmap3[i, j], heatmap[i, j] = KL_divergence_pinv(mean1, mean2, covariance1, covariance2)\n",
    "        heatmap[i, j] = KL_divergence_std(mean1, mean2, covariance1, covariance2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "plt.imshow(heatmap)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(heatmap1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(heatmap2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(heatmap3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = './class_barycenter/COCO_train'\n",
    "mean = [x for x in sorted(os.listdir(path),\n",
    "                          key=lambda item: (int(item.partition('_')[0])\n",
    "                                            if item[0].isdigit() else float('inf'), item))\n",
    "        if x.split('_')[1] == 'mean.pkl']\n",
    "\n",
    "cov = [x for x in sorted(os.listdir(path),\n",
    "                         key=lambda item: (int(item.partition('_')[0])\n",
    "                                           if item[0].isdigit() else float('inf'), item))\n",
    "       if x.split('_')[1] == 'cov.pkl']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean1_path = os.path.join(path, mean[70])\n",
    "cov1_path = os.path.join(path, cov[70])\n",
    "with open(mean1_path, 'rb') as f:\n",
    "    mean1 = pickle.load(f)\n",
    "with open(cov1_path, 'rb') as f:\n",
    "    covariance1 = pickle.load(f)\n",
    "\n",
    "mean2_path = os.path.join(path, mean[0])\n",
    "cov2_path = os.path.join(path, cov[0])\n",
    "with open(mean2_path, 'rb') as f:\n",
    "    mean2 = pickle.load(f)\n",
    "with open(cov2_path, 'rb') as f:\n",
    "    covariance2 = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean1 = mean1.type(torch.float64)\n",
    "mean2 = mean2.type(torch.float64)\n",
    "covariance1 = covariance1.type(torch.float64)\n",
    "covariance2 = covariance2.type(torch.float64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.isclose(np.linalg.eig(covariance1.cpu().numpy())[0], np.zeros(1024)).sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KL_divergence(mean1, mean2, covariance1, covariance2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KL_divergence_pinv(mean1, mean2, covariance1, covariance2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KL_divergence_std(mean1, mean2, covariance1, covariance2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "product2 = covariance2 @ torch.linalg.pinv(covariance1, atol=1e-7, hermitian=True)\n",
    "trace = torch.trace(product2) + (\n",
    "        1024 - torch.linalg.matrix_rank(torch.linalg.pinv(covariance1, atol=1e-7, hermitian=True)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trace"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "paths = sorted(os.path.join('./class_barycenter', dataset) for dataset in os.listdir('./class_barycenter'))\n",
    "for path in paths:\n",
    "    print(path.split('/')[-1])\n",
    "\n",
    "    cov = [x for x in sorted(os.listdir(path),\n",
    "                             key=lambda item: (int(item.partition('_')[0])\n",
    "                                               if item[0].isdigit() else float('inf'), item))\n",
    "           if x.split('_')[1] == 'cov.pkl']\n",
    "\n",
    "    n = len(cov)\n",
    "\n",
    "    for i in range(n):\n",
    "        cov1_path = os.path.join(path, cov[i])\n",
    "        with open(cov1_path, 'rb') as f:\n",
    "            covariance1 = pickle.load(f)\n",
    "\n",
    "        variance1 = np.array([covariance1[i, i].cpu().numpy() for i in range(len(covariance1))])\n",
    "\n",
    "        try:\n",
    "            print(\n",
    "                i,\n",
    "                (np.linalg.eig(covariance1.cpu().numpy())[0] <= np.linalg.eig(covariance1.cpu().numpy())[\n",
    "                    0].max() * 0.001).sum()\n",
    "            )\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(i)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(np.linalg.eig(covariance1.cpu().numpy())[0] > 5).sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(cov1_path, 'rb') as f:\n",
    "    covariance1 = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('./dataset_barycenter/COCO_train_std.pkl', 'rb') as f:\n",
    "    cov = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cov.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.listdir('./dataset_barycenter')\n",
    "\n",
    "np.isclose(np.linalg.eig(cov.cpu().numpy())[0], np.zeros(cov.shape[0]), atol=1e-6).sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = './dataset_barycenter'\n",
    "\n",
    "cov = [x for x in sorted(os.listdir(path)) if x.split('_')[-1] == 'std.pkl']\n",
    "\n",
    "for dataset in cov:\n",
    "    cov_path = os.path.join(path, dataset)\n",
    "    with open(cov_path, 'rb') as f:\n",
    "        covariance = pickle.load(f)\n",
    "\n",
    "    variance = np.array([covariance[i, i].cpu().numpy() for i in range(len(covariance))])\n",
    "\n",
    "    print(\n",
    "        dataset,\n",
    "        (np.linalg.eig(covariance.cpu().numpy())[0] <= np.linalg.eig(covariance.cpu().numpy())[0].max() * 0.001).sum()\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prop_eig0 = [773.45, 703.25, 808.60,\n",
    "             776.25, 716.19, 833.06,\n",
    "             968.71, 872.29, 1002.20,\n",
    "             888.60, 834.20, 887.00,\n",
    "             970.85, 976.40, 1007.89]\n",
    "# 549.80, 549.80, 684.40]\n",
    "\n",
    "perf_5shot = [30.42, 30.42, 30.42,\n",
    "              14.45, 14.45, 14.45,\n",
    "              55.58, 55.58, 55.58,\n",
    "              13.25, 13.25, 13.25,\n",
    "              5.26, 5.26, 5.26]\n",
    "# 5.74, 5.74, 5.74]\n",
    "\n",
    "labels = ['DIOR_test', 'DIOR_train', 'DIOR_val',\n",
    "          'DOTA_test', 'DOTA_train', 'DOTA_val',\n",
    "          'DeepFruits_test', 'DeepFruits_train', 'DeepFruits_val',\n",
    "          'SIXray_test', 'SIXray_train', 'SIXray_val',\n",
    "          'clipart_test', 'clipart_train', 'clipart_val']\n",
    "# 'VisDrone_test', 'VisDrone_train', 'VisDrone_val']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors_dict = {'COCO': '#9D6FD7',\n",
    "               'CrowdHuman': '#E6C8C7',\n",
    "               'DIOR': '#003A37',\n",
    "               'DOTA': '#8AFF66',\n",
    "               'DeepFruits': '#284D26',\n",
    "               'KITTI': '#F65794',\n",
    "               'Oktoberfest': '#804E96',\n",
    "               'SIXray': '#C05E5A',\n",
    "               'VisDrone': '#458BBC',\n",
    "               'clipart': '#C83F0F',\n",
    "               'comic': '#3C7503',\n",
    "               'fashionpedia': '#3B9F21',\n",
    "               'watercolor': '#E68C70'}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for prop, perf, label in zip(prop_eig0, perf_5shot, labels):\n",
    "    if label.split('_')[-1] == 'test':\n",
    "        plt.scatter(prop, perf, color=colors_dict[label.split('_')[0]])\n",
    "        plt.text(prop, perf + 1, label.split('_')[0])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prop_eig0 = [970.85, 976.40, 1007.89,\n",
    "             856.00, 860.00, 862.00,\n",
    "             968.71, 872.29, 1002.20,\n",
    "             891.89, 872.17, 949.87,\n",
    "             855.00, 836.50, 856.75,\n",
    "             1009.33, 925.73, 992.07,\n",
    "             888.60, 834.20, 887.00]\n",
    "# 549.80, 549.80, 684.40]\n",
    "\n",
    "perf_5shot = [49.3, 49.3, 49.3,\n",
    "              51.5, 51.5, 51.5,\n",
    "              60.7, 60.7, 60.7,\n",
    "              21.3, 21.3, 21.3,\n",
    "              45.3, 45.3, 45.3,\n",
    "              81.6, 81.6, 81.6,\n",
    "              23.9, 23.9, 23.9]\n",
    "# 14.2, 14.2, 14.2]\n",
    "\n",
    "labels = ['clipart_test', 'clipart_train', 'clipart_val',\n",
    "          'CrowdHuman_test', 'CrowdHuman_train', 'CrowdHuman_val',\n",
    "          'DeepFruits_test', 'DeepFruits_train', 'DeepFruits_val',\n",
    "          'fashionpedia_test', 'fashionpedia_train', 'fashionpedia_val',\n",
    "          'KITTI_test', 'KITTI_train', 'KITTI',\n",
    "          'Oktoberfest_test', 'Oktoberfest_train', 'Oktoberfest_val',\n",
    "          'SIXray_test', 'SIXray_train', 'SIXray_val']\n",
    "# 'VisDrone_test', 'VisDrone_train', 'VisDrone_val']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 13})\n",
    "for prop, perf, label in zip(prop_eig0, perf_5shot, labels):\n",
    "    if label.split('_')[-1] == 'test':\n",
    "        plt.scatter(prop, perf, color=colors_dict[label.split('_')[0]])\n",
    "        plt.text(prop, perf + 1, label.split('_')[0])\n",
    "plt.xlabel(r\"Difficulté $\\varepsilon$\")\n",
    "plt.ylabel(\"AP50 5-shot\")\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
