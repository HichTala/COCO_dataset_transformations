{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets.coco import CocoDetection as CocoDataset\n",
    "from resnet import ResNet\n",
    "from super_pycocotools.coco import SuperCOCO\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import build_detection_train_loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing DeepFruits\n",
      "train data\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "processing SIXray\n",
      "train data\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "test data\n",
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "super_ann_file = './datasets.json'\n",
    "coco = SuperCOCO(super_ann_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_dir = coco.DeepFruits.infos['root']\n",
    "data_type = 'train2017'\n",
    "img_dir = '{}/{}/'.format(data_dir, data_type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.DATASETS.TRAIN = coco.DeepFruits.register()[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "cfg.SOLVER.IMS_PER_BATCH = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "dataloader = build_detection_train_loader(cfg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "resnet = ResNet(cfg).cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "data = next(iter(dataloader))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for data in dataloader:\n",
    "    outputs = resnet(data)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 1024])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from detectron2.modeling import build_backbone"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "backbone = build_backbone(cfg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (stem): BasicStem(\n    (conv1): Conv2d(\n      3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n      (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n    )\n  )\n  (res2): Sequential(\n    (0): BottleneckBlock(\n      (shortcut): Conv2d(\n        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n      (conv1): Conv2d(\n        64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n      )\n      (conv2): Conv2d(\n        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n      )\n      (conv3): Conv2d(\n        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n    )\n    (1): BottleneckBlock(\n      (conv1): Conv2d(\n        256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n      )\n      (conv2): Conv2d(\n        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n      )\n      (conv3): Conv2d(\n        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n    )\n    (2): BottleneckBlock(\n      (conv1): Conv2d(\n        256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n      )\n      (conv2): Conv2d(\n        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n      )\n      (conv3): Conv2d(\n        64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n    )\n  )\n  (res3): Sequential(\n    (0): BottleneckBlock(\n      (shortcut): Conv2d(\n        256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n        (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n      )\n      (conv1): Conv2d(\n        256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n      )\n      (conv2): Conv2d(\n        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n      )\n      (conv3): Conv2d(\n        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n      )\n    )\n    (1): BottleneckBlock(\n      (conv1): Conv2d(\n        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n      )\n      (conv2): Conv2d(\n        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n      )\n      (conv3): Conv2d(\n        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n      )\n    )\n    (2): BottleneckBlock(\n      (conv1): Conv2d(\n        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n      )\n      (conv2): Conv2d(\n        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n      )\n      (conv3): Conv2d(\n        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n      )\n    )\n    (3): BottleneckBlock(\n      (conv1): Conv2d(\n        512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n      )\n      (conv2): Conv2d(\n        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n      )\n      (conv3): Conv2d(\n        128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n      )\n    )\n  )\n  (res4): Sequential(\n    (0): BottleneckBlock(\n      (shortcut): Conv2d(\n        512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n        (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n      )\n      (conv1): Conv2d(\n        512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n      (conv2): Conv2d(\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n      (conv3): Conv2d(\n        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n      )\n    )\n    (1): BottleneckBlock(\n      (conv1): Conv2d(\n        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n      (conv2): Conv2d(\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n      (conv3): Conv2d(\n        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n      )\n    )\n    (2): BottleneckBlock(\n      (conv1): Conv2d(\n        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n      (conv2): Conv2d(\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n      (conv3): Conv2d(\n        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n      )\n    )\n    (3): BottleneckBlock(\n      (conv1): Conv2d(\n        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n      (conv2): Conv2d(\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n      (conv3): Conv2d(\n        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n      )\n    )\n    (4): BottleneckBlock(\n      (conv1): Conv2d(\n        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n      (conv2): Conv2d(\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n      (conv3): Conv2d(\n        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n      )\n    )\n    (5): BottleneckBlock(\n      (conv1): Conv2d(\n        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n      (conv2): Conv2d(\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n      )\n      (conv3): Conv2d(\n        256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n        (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n      )\n    )\n  )\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone.to('cuda')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "images = resnet.preprocess_image(data)\n",
    "features = backbone(images.tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['res4']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "CfgNode({'NAME': 'RPN', 'MIN_SIZE': 0})"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.MODEL.PROPOSAL_GENERATOR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "features = [features[f] for f in features.keys()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 1024, 50, 68])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 1024, 50, 68])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cat(features).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "CfgNode({'DEPTH': 50, 'OUT_FEATURES': ['res4'], 'NUM_GROUPS': 1, 'NORM': 'FrozenBN', 'WIDTH_PER_GROUP': 64, 'STRIDE_IN_1X1': True, 'RES5_DILATION': 1, 'RES2_OUT_CHANNELS': 256, 'STEM_OUT_CHANNELS': 64, 'DEFORM_ON_PER_STAGE': [False, False, False, False], 'DEFORM_MODULATED': False, 'DEFORM_NUM_GROUPS': 1})"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.MODEL.RESNETS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "0\n",
      "{}\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "output1 = resnet(data)\n",
    "output2 = resnet(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from detectron2.checkpoint import DetectionCheckpointer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = \"https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_C4_1x/137257644/model_final_721ade.pkl\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001B[35mproposal_generator.rpn_head.conv.{bias, weight}\u001B[0m\n",
      "  \u001B[35mproposal_generator.rpn_head.objectness_logits.{bias, weight}\u001B[0m\n",
      "  \u001B[35mproposal_generator.rpn_head.anchor_deltas.{bias, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.0.shortcut.weight\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.0.shortcut.norm.{bias, running_mean, running_var, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.0.conv1.weight\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.0.conv1.norm.{bias, running_mean, running_var, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.0.conv2.weight\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.0.conv2.norm.{bias, running_mean, running_var, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.0.conv3.weight\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.0.conv3.norm.{bias, running_mean, running_var, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.1.conv1.weight\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.1.conv1.norm.{bias, running_mean, running_var, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.1.conv2.weight\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.1.conv2.norm.{bias, running_mean, running_var, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.1.conv3.weight\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.1.conv3.norm.{bias, running_mean, running_var, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.2.conv1.weight\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.2.conv1.norm.{bias, running_mean, running_var, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.2.conv2.weight\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.2.conv2.norm.{bias, running_mean, running_var, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.2.conv3.weight\u001B[0m\n",
      "  \u001B[35mroi_heads.res5.2.conv3.norm.{bias, running_mean, running_var, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.box_predictor.cls_score.{bias, weight}\u001B[0m\n",
      "  \u001B[35mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'__author__': 'Detectron2 Model Zoo'}"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = DetectionCheckpointer(resnet)\n",
    "checkpointer.load(cfg.MODEL.WEIGHTS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "output3 = resnet(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(True, device='cuda:0')"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output2 == output1).all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(False, device='cuda:0')"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output2 == output3).all()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1024])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([output3.mean(0).unsqueeze(0)]).mean(0).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
